{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to implement a digit classification neural network that will predict a handwritten digit between the values 0 and 9. The images used to train and validate te model will come from the **MNIST** dataset which is a public dataset of 28x28, grayscale, and handwritten image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import opendatasets as od   # For grabbing our dataset\n",
    "from matplotlib import pyplot as plt    # Mainly used to display the images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by grabbing the dataset.\n",
    "\n",
    "In this example, we will be using the MNIST dataset from Kaggle, so we will need an account and a `kaggle.json` that will give us permission to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\digit-recognizer\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/competitions/digit-recognizer/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, let's take the data and save them as `pandas` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_data = pd.read_csv(\"digit-recognizer/train.csv\")\n",
    "raw_test_data = pd.read_csv(\"digit-recognizer/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the data are saved as `pandas` objects. Let's make them `numpy` arrays so we can do mathmatical operations on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: 42000\n",
      "Features: 785\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(raw_train_data)\n",
    "test_data = np.array(raw_test_data)\n",
    "rows, cols = train_data.shape   # show the number of examples and features\n",
    "print(f\"Examples: {rows}\")\n",
    "print(f\"Features: {cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently our data is reflecting 42000 examples with 784 features (pixels) each. We should transpose this data so that we the rows and columns represents features and data respecitively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first example in the training: (785, 42000)\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.T\n",
    "test_data = test_data.T\n",
    "print(f\"Shape of the first example in the training: {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our data is now features x examples. \n",
    "\n",
    "Since our labels are still mixed within the features of the data, lets make sure we take keep the inputs and labels apart. We will have a `X` that will be of shape features x examples and a `Y` that will have the shape equivilent to the number of examples we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training inputs: (784, 42000)\n",
      "Shape of training labels: (42000,)\n"
     ]
    }
   ],
   "source": [
    "Y_train = train_data[0]\n",
    "X_train = train_data[1:]\n",
    "X_train = X_train / 255\n",
    "\n",
    "Y_test = test_data[0]\n",
    "X_test = test_data[1:]\n",
    "X_test = X_test / 255\n",
    "\n",
    "print(f\"Shape of training inputs: {X_train.shape}\")\n",
    "print(f\"Shape of training labels: {Y_train.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data all cleaned up, we can begin making our neural network.\n",
    "\n",
    "We will be making a 3 layered, 1 hidden layer neural network.\n",
    "\n",
    "- input layer\n",
    "- hidden layer\n",
    "- output layer\n",
    "\n",
    "For the input and hidden layers, they will need their own weights and biases where the shapes are:\n",
    "\n",
    "- weight = number_of outputs x number_of_inputs\n",
    "- bias = number_of outputs x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params():\n",
    "    w1 = np.random.rand(10, 784) - 0.5\n",
    "    b1 = np.random.rand(10, 1) - 0.5\n",
    "    w2 = np.random.rand(10, 10) - 0.5\n",
    "    b2 = np.random.rand(10, 1) - 0.5\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make our forward propagation logic. Our input and hidden layer will perform the same linear operation on their inputs, but they will have different activation functions before passing their results to the next layer.\n",
    "\n",
    "Our linear operation will be $weights * inputs + bias$ where we are getting the dot product between the weight and input matrix. \n",
    "\n",
    "For our input layer, we will use the ReLU activation and for our hidden, we will use the sigmoid activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "def softmax(z):\n",
    "    return np.exp(z) / sum(np.exp(z))\n",
    "\n",
    "def forward_prop(w1, b1, w2, b2, X):\n",
    "    # Input layer\n",
    "    z1 = w1.dot(X) + b1\n",
    "    a1 = ReLU(z1)   # ReLU activation\n",
    "\n",
    "    # Hidden layer\n",
    "    z2 = w2.dot(a1) + b2\n",
    "    a2 = softmax(z2)    # Sigmoid activation\n",
    "    return z1, a1, z2, a2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next component we need is backpropagation that will go back through our neural network and update the weights and bias according to the output. To achieve this, we need to accomplish a few tasks.\n",
    "\n",
    "1. One hot encode `Y` (he process of representing categorical data as 0s and 1s)\n",
    "2. Get the error of each outputed layer (hidden and ouput)\n",
    "3. Get the gradients of the cost function with respect to the weights and biases of that layer\n",
    "4. Update the weigths and biases with the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deriv_ReLU(z):\n",
    "    return z > 0\n",
    "\n",
    "def one_hot(Y):\n",
    "    \"\"\"\n",
    "    This function follows these steps:\n",
    "    1. make a matrix of all 0s of size [examples x labels]\n",
    "    2. Generate an array of numbers 0 -> 41999.\n",
    "    3. By using the array of numbers to go through the rows in the 0s matrix\n",
    "       and Y to go through the columns, set that value to 1\n",
    "    4. Transpose the modified 0s matrix\n",
    "    \"\"\"\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1)) \n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1 # Steps 2 and 3\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "def back_prop(z1, a1, z2, a2, w1, w2, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot(Y)\n",
    "    \n",
    "    dz2 = a2 - one_hot_Y            # Get the error of the output layer\n",
    "    dw2 = 1 / m * dz2.dot(a1.T)     # Get the gradient of the cost function with respect to the weights of the second layer\n",
    "    db2 = 1 / m * np.sum(dz2)    # Get the gradient of the cost function with respect to the bias of the second layer\n",
    "\n",
    "    dz1 = w2.T.dot(dz2) * deriv_ReLU(z1)    # Get the error of the hidden layer\n",
    "    dw1 = 1 / m * dz1.dot(X.T)              # Get the gradient of the cost function with respect to the weights of the first layer\n",
    "    db1 = 1 / m * np.sum(dz1)            # Get the gradient of the cost function with respect to the bias of the first layer\n",
    "    return dw1, db1, dw2, db2\n",
    "\n",
    "def update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha):\n",
    "    w1 = w1 - alpha * dw1\n",
    "    b1 = b1 - alpha * db1\n",
    "    w2 = w2 - alpha * dw2\n",
    "    b2 = b2 - alpha * db2\n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, with backpropagation and param updation working, we now have a way to modify our weights and biases which is the foundation for training. Now we need to implement **gradient descent** so we can keep adjusting these weights properly over multiple interations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(a2):\n",
    "    return np.argmax(a2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y) / Y.size\n",
    "\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    w1, b1, w2, b2 = init_params()\n",
    "    for i in range(iterations):\n",
    "        z1, a1, z2, a2 = forward_prop(w1, b1, w2, b2, X)\n",
    "        dw1, db1, dw2, db2 = back_prop(z1, a1, z2, a2, w1, w2, X, Y)\n",
    "        w1, b1, w2, b2 = update_params(w1, b1, w2, b2, dw1, db1, dw2, db2, alpha)\n",
    "        if i % 50 == 0 or i == iterations-1:\n",
    "            print(f\"Iteraation: {i}\\tAccuracy: {get_accuracy(get_predictions(a2), Y)}\")\n",
    "    return w1, b1, w2, b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteraation: 0\tAccuracy: 0.04830952380952381\n",
      "Iteraation: 50\tAccuracy: 0.7195238095238096\n",
      "Iteraation: 100\tAccuracy: 0.8093095238095238\n",
      "Iteraation: 150\tAccuracy: 0.8468095238095238\n",
      "Iteraation: 200\tAccuracy: 0.8672619047619048\n",
      "Iteraation: 250\tAccuracy: 0.8844761904761905\n",
      "Iteraation: 300\tAccuracy: 0.8921666666666667\n",
      "Iteraation: 350\tAccuracy: 0.8977857142857143\n",
      "Iteraation: 400\tAccuracy: 0.9027380952380952\n",
      "Iteraation: 450\tAccuracy: 0.9057857142857143\n",
      "Iteraation: 500\tAccuracy: 0.9078571428571428\n",
      "Iteraation: 550\tAccuracy: 0.9115714285714286\n",
      "Iteraation: 600\tAccuracy: 0.9136428571428571\n",
      "Iteraation: 650\tAccuracy: 0.9154761904761904\n",
      "Iteraation: 700\tAccuracy: 0.917404761904762\n",
      "Iteraation: 750\tAccuracy: 0.9188571428571428\n",
      "Iteraation: 800\tAccuracy: 0.9200238095238096\n",
      "Iteraation: 850\tAccuracy: 0.9210714285714285\n",
      "Iteraation: 900\tAccuracy: 0.9229285714285714\n",
      "Iteraation: 950\tAccuracy: 0.9237142857142857\n",
      "Iteraation: 999\tAccuracy: 0.9245714285714286\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = gradient_descent(X_train, Y_train, 1000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 7\tLabel: 7\n"
     ]
    }
   ],
   "source": [
    "def make_prediction(index, X, Y, w1, b1, w2, b2):\n",
    "    _, _, _, a2 = forward_prop(w1, b1, w2, b2, X)\n",
    "    predictions = get_predictions(a2)\n",
    "    \n",
    "    target_image = X[:, index].reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(target_image, interpolation=\"nearest\")\n",
    "    plt.show()\n",
    "    print(f\"Prediction: {predictions[index]}\\tLabel: {Y[index]}\")\n",
    "\n",
    "random_index = np.random.randint(len(X_train), size=1)[0]\n",
    "make_prediction(random_index, X_train, Y_train, w1, b1, w2, b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
